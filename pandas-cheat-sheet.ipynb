{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas Cheat Sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Series:\n",
    "\n",
    "### 1. Creation (by what):\n",
    "    - array object (numpy array)\n",
    "    - dictionary (key-value pairs): key -> index, value -> value\n",
    "    - tuple\n",
    "    - set, be careful if the data structure is not an ordered values\n",
    "### 2. Attributes:\n",
    "    - values\n",
    "    - index\n",
    "        - Attributes: name\n",
    "    - dtype\n",
    "### 3. Parameters:\n",
    "    - data\n",
    "    - index\n",
    "    - dtype\n",
    "    - name\n",
    "### 4. Methods:\n",
    "    - isnull\n",
    "    - notnull\n",
    "    - reindex:\n",
    "        - Parameters:\n",
    "            - index\n",
    "            - method: 'ffill' -> forward fill\n",
    "             - fill_value: substitute value to use when introducing missing data by reindexing.\n",
    "            - limit: when forward- or backfilling, maximum size gap (in number of elements) to fill.\n",
    "            - tolerance: when forward- or backfilling, maximum size gap (in absolute numeric distance) to fill for inexact matches.\n",
    "    - drop: \n",
    "        - Parameters:\n",
    "            - labels: list-like\n",
    "            - inplace: edit the Series, deleting the old one\n",
    "    - add, sub, div, mul:\n",
    "        - Parameters:\n",
    "            - fill_value: fill nan by specified value\n",
    "    - apply:\n",
    "        - Parameters:\n",
    "            - function\n",
    "            - axis\n",
    "    - applymap: apply and map (probably also casting)\n",
    "    - sort_index:\n",
    "        - Parameters:\n",
    "            - ascending: default -> True\n",
    "    - sort_values: nan will be place at the end\n",
    "    - rank:\n",
    "        - Parameters:\n",
    "            - ascending\n",
    "            - method\n",
    "    - Aggregation functions: mean, sum, median, etc\n",
    "        - skipna: If False, the null values are not excluded\n",
    "    - idxmax: return the index label of max value\n",
    "    - idxmin: return the index label of min value\n",
    "    - cumsum: cumulative sum\n",
    "    - describe: returns summary statistics. On non-numeric data returns alternative summary statistics\n",
    "    - argmax, argmin: return index position\n",
    "    - corr: correlations\n",
    "    - cov: covariances\n",
    "    - unique: returns array\n",
    "    - value_counts: returns Series\n",
    "    - isin: returns boolean array\n",
    "    - match: compute integer indices for each value in an array into another array of distinct values; helpful for data alignment and join-type operations\n",
    "    - fillna: fill null values by specified value\n",
    "    - sample: taking sample as many as the specified argument\n",
    "### 5. Accessing: numpy style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. DataFrame:\n",
    "\n",
    "### 1. Creation (by what):\n",
    "    - array object (numpy array)\n",
    "    - dictionary containing key-list_of_values\n",
    "    - dictionary of dictionary: outer -> column label, inner -> index label\n",
    "    - dictionary of arrays, lists or tuples\n",
    "    - dictionary of Series\n",
    "    - list of dicts or Series\n",
    "    - list of lists\n",
    "### 2. Attributes:\n",
    "    - index\n",
    "        - Attributes: name\n",
    "    - columns\n",
    "        - Attributes: name\n",
    "    - dtypes\n",
    "    - values: return ndarray\n",
    "### 3. Parameters:\n",
    "    - data\n",
    "    - index\n",
    "    - columns\n",
    "    - dtype\n",
    "### 4. Methods:\n",
    "    - head: return the first five rows\n",
    "    - tail: return the last five rows\n",
    "    - transpose (dataframe.T)\n",
    "    - isnull\n",
    "    - notnull\n",
    "    - reindex:\n",
    "        - Parameters:\n",
    "            - index\n",
    "            - columns\n",
    "            - method: 'ffill' -> forward fill\n",
    "            - fill_value: substitute value to use when introducing missing data by reindexing.\n",
    "            - limit: when forward- or backfilling, maximum size gap (in number of elements) to fill.\n",
    "            - tolerance: when forward- or backfilling, maximum size gap (in absolute numeric distance) to fill for inexact matches.\n",
    "    - drop:\n",
    "        - Parameters:\n",
    "            - labels\n",
    "            - axis: 0 -> along row (row labels), 1 -> along column (column labels)\n",
    "            - inplace: edit the data frame, delete the old one\n",
    "    - add, sub, div, mul:\n",
    "        - Parameters:\n",
    "            - fill_value: fill nan by specified value\n",
    "    - apply:\n",
    "        - Parameters:\n",
    "            - function\n",
    "            - axis: 0 -> along column, 1 -> along row\n",
    "    - applymap: apply and map (probably also casting)\n",
    "    - sort_index:\n",
    "        - Parameters:\n",
    "            - axis: 0 -> index label, 1 -> columns label\n",
    "            - ascending: default -> True\n",
    "    - sort_values:\n",
    "        - Parameters:\n",
    "            - axis: 0 -> index label, 1 -> columns label\n",
    "            - ascending: default -> True\n",
    "            - by: specifying based on which label\n",
    "    - rank:\n",
    "        - Parameters:\n",
    "            - ascending\n",
    "            - method\n",
    "            - axis\n",
    "    - Aggregation functions: mean, sum, median, etc\n",
    "        - axis: 0 -> along column, 1 -> along row\n",
    "        - skipna: If False, null values are not excluded\n",
    "    - idxmax: returns the index label of max value\n",
    "    - idxmin: returns the index label of min value\n",
    "    - cumsum: cumulative sum\n",
    "    - describe: returns summary statistics. On non-numeric data returns alternative summary statistics\n",
    "    - argmax, argmin: return index position\n",
    "    - corr: correlations\n",
    "    - cov: covariances\n",
    "    - corrwith: compute pair-wise correlations\n",
    "    - unique: returns array\n",
    "    - value_counts: returns Series\n",
    "    - isin: returns boolean array\n",
    "    - match: compute integer indices for each value in an array into another array of distinct values; helpful for data alignment and join-type operations\n",
    "    - fillna: fill null values by specified value\n",
    "### 5. Accessing: \n",
    "    - numpy style\n",
    "    - loc, label based\n",
    "    - iloc,  position based\n",
    "    - at\n",
    "    - iat  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Index Objects:\n",
    "\n",
    "### 1. Creation:\n",
    "    - list, tuple\n",
    "### 2. Methods:\n",
    "    - append: concatenate additional Index object, return a new object\n",
    "    - difference: compute set difference\n",
    "    - intersection: compute set intersection\n",
    "    - union: compute set union\n",
    "    - isin: returns boolean array with parameter arraylike\n",
    "    - is_monotonic: returns True if each element is greater than or equal to the previous element\n",
    "    - is_unique\n",
    "    - unique\n",
    "    - get_indexer: returns the index of argument based on index it provides\n",
    "### 3. Attributes: \n",
    "    - name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Common functions:\n",
    "\n",
    "- Mostly each instance methods also have its general functions\n",
    "- null:\n",
    "    - isnull\n",
    "    - notnull\n",
    "- pd.crosstab: returns cross-tabulation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Data loading, Storage, and File Formats:\n",
    "\n",
    "### 1. Parsing functions:\n",
    "    - read_csv: Load delimited data from a file, URL, or file-like object; use comma as default delimiter\n",
    "        - Parameters:\n",
    "            - filepath: file path \n",
    "            - header: True, the first row will be header\n",
    "            - sep: separator\n",
    "            - names: column labels\n",
    "            - index_col: column that we want to be index label, if provided list, index will be hierarchical form\n",
    "            - skiprows: skip specified rows\n",
    "            - na_values: the specified arguments will be treated as null, provided as dict (key as column label, value as list of element)\n",
    "            - nrows: only takes the specified amount of rows\n",
    "            - chunksize: take number of pieces, return TextFileReader\n",
    "    - read_table: Load delimited data from a file, URL, or file-like object; use tab ('\\t') as default delimiter\n",
    "    - read_fwf: Read data in fixed-width column format (i.e., no delimiters)\n",
    "    - read_clipboard: Version of read_table that reads data from the clipboard; useful for converting tables from web pages\n",
    "    - read_excel: Read tabular data from an Excel XLS or XLSX file\n",
    "    - read_hdf: Read HDF5 files written by pandas\n",
    "    - read_html: Read all tables found in the given HTML document\n",
    "    - read_json: Read data from a JSON (JavaScript Object Notation) string representation\n",
    "    - read_msgpack: Read pandas data encoded using the MessagePack binary format\n",
    "    - read_pickle: Read an arbitrary object stored in Python pickle format\n",
    "    - read_sas: Read a SAS dataset stored in one of the SAS system’s custom storage formats\n",
    "    - read_sql: Read the results of a SQL query (using SQLAlchemy) as a pandas DataFrame\n",
    "    - read_stata: Read a dataset from Stata file format\n",
    "    - read_feather: Read the Feather binary file format\n",
    "### 2. Write (instance method of dataframe):\n",
    "    - to_csv:\n",
    "        - Parameters:\n",
    "            - filename\n",
    "            - sep: separator\n",
    "            - na_rep: the argument will be the text for missing values\n",
    "            - index: If false, no index included\n",
    "            - header: If false, no header\n",
    "            - columns: list of column label\n",
    "### 3. JSON file:\n",
    "    - json module\n",
    "    - json.load: load the str to dict\n",
    "    - json.dumps: back to str\n",
    "    - pd.read_json: incase for good form of json file\n",
    "    - df.to_json: make json file from data frame\n",
    "### 4. HTML:\n",
    "    - pd.read_html\n",
    "    - df.to_html\n",
    "### 5. Pickle:\n",
    "    - pd.read_pickle\n",
    "    - df.to_pickle\n",
    "### 6. HDF5:\n",
    "    - pd.HDFStore: returns HDFStore object (think it as a storage like dict)\n",
    "    - Methods for HDFStore object:\n",
    "        - store.put('storage_name', format=<\\table> or <\\fixed>)\n",
    "        - store.select('storage_name', where=[conditions involvind index]\n",
    "    - pandas:\n",
    "        - pd.read_hdf, ex: pd.read_hdf('hdf_file', 'storage_name', where)\n",
    "        - frame.to_hdf('file_name', 'storage_name', format)\n",
    "### 7. Excel:\n",
    "    - pd.ExcelFile: for read excel file\n",
    "    - pd.ExcelWriter: for write excel file\n",
    "    - pd.read_excel: read \n",
    "    - df.to_csv: write\n",
    "### 8. Web APIs:\n",
    "    - import request: a module\n",
    "    - resp = request.get(url): get the url\n",
    "    - resp.json(): returns list of dict, then turn it into dataframe\n",
    "### 9. Databases:\n",
    "    - Module: sqlite3\n",
    "    - Methods: sqlite3.connect(), create a data base\n",
    "    - database.execute(query)\n",
    "    - con.commit()\n",
    "    - Simple:\n",
    "        - import sqlalchemy as sqla\n",
    "        - db = sqla.create_engine(sqlite:///mydata.sqlite)\n",
    "        - pd.read_sql('SELECT * FROM test, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Data Cleaning and Preparation Functionalities\n",
    "\n",
    "### 1. Handling Missing Data\n",
    "    - Methods:\n",
    "        - isnull: returns boolean pandas object, True if null, False otherwise\n",
    "        - notnull: negation of isnull method\n",
    "        - dropna: returns pandas object withoout null values\n",
    "            - how: specifying all or any\n",
    "            - axis: 0 along row, 1 along column\n",
    "            - thresh: specifies # of non-null values\n",
    "        - fillna: fill null value with specified value\n",
    "            - value: single value, dict(key->column label, value-value to replaced)\n",
    "            - inplace: edit, delete old one\n",
    "            - method: 'ffill' -> forward fill\n",
    "            - limit: specifies the number of missing values filled by method kwarg\n",
    "            - axis: 0 along column, 1 along row\n",
    "### 2. Data Transformation\n",
    "    - Methods:\n",
    "        - duplicated: returns boolean pandas object, True if the object is a duplicate\n",
    "        - drop_duplicates: removing duplicate values\n",
    "            - subset: subset of column labels\n",
    "            - keep: 'first' keeps the first observed data, 'last' keeps the last observed data \n",
    "        - map: takes dict or function returns pandas object\n",
    "        - replace: replace the old value with new one. Can be a tuple, or dict\n",
    "        - rename: index, columns. Rename the index\n",
    "        - take: return the elements in the given *positional* indices along an axis.\n",
    "        - sample:taking sample\n",
    "            - n: number of samples\n",
    "            - replace: True with replacement, False otherwise\n",
    "        - join: concatenate \n",
    "    - Functions:\n",
    "        - cut: returns Categorical object\n",
    "            - x: array\n",
    "            - bins\n",
    "            - labels: rename the Categorical labels, if false the index are used\n",
    "            - precision: if bins=int, this specifies floating-point accuracy\n",
    "            - Categorical object attributes:\n",
    "                - codes\n",
    "                - categories\n",
    "        - qcut: same as cut, but cut it into its quartiles. Will be roughly equal size\n",
    "        - get_dummies: making dummy variables\n",
    "            - data\n",
    "            - prefix: give a dummy variable prefix, with suffix new column label\n",
    "        - add_prefix: adding prefix to column labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. Data Wrangling:\n",
    "\n",
    "### 1. Hierarchical Indexing\n",
    "    - Creation:\n",
    "        - Series: specifying the index as list of list (levels)\n",
    "        - MultiIndex.from_arrays\n",
    "    - Methods: \n",
    "        - unstack: Hierarchical Series to DataFrame\n",
    "        - stack: reverse of unstack\n",
    "        - swaplevel: swap the level in hierarchical pandas object\n",
    "        - sort_index: argument level\n",
    "        - Summary Statistics:\n",
    "            - level\n",
    "            - axis: 0 along row, 1 along column\n",
    "        - set_index: the specified columns will be index, if argument is a list it will be hierarchical index\n",
    "            - drop: by default it removed the specified columns, False if dont remove\n",
    "### 2. Combining and Merging\n",
    "    - merge (function): joining dataset using key\n",
    "        - left: data\n",
    "        - right: data\n",
    "        - how: inner is intersection, outer is union\n",
    "        - on: specify both key, left and right. must have the same key name\n",
    "        - left_on: key on left\n",
    "        - right_on: key on right\n",
    "        - left_index: using index as key from left data\n",
    "        - right_index: using index as key from right data\n",
    "        - suffixes: if there are overlapping columns\n",
    "    - join (method): mostly the same as merge\n",
    "    - concat (function): like np.concatenate\n",
    "        - objs: objects\n",
    "        - join: inner is intersection, outer is union\n",
    "        - join_axes: specifies the label want to be included in return\n",
    "        - axis: 0 is vertical, 1 is horizontal\n",
    "        - keys: if axis 0, keys be index, if axis 1, keys will be column label\n",
    "        - names: specifies the name of level in hierarchical indexed data\n",
    "        - ignore_index: ignoring index when concatenating\n",
    "        - verify_intergrity\n",
    "    - combine_first (method): take first, if nan take not nan\n",
    "### 3. Reshaping and Pivoting\n",
    "    - unstack (method): hierarchical -> common df\n",
    "        - level\n",
    "    - stack (method): df -> hierarhical (Series)\n",
    "        - dropna: if True (default), when stack missing values gone, False otherwise\n",
    "    - pivot (method): (long to wide), single column to multiple columns\n",
    "        - index: what column to be the index lable\n",
    "        - columns: what column to be the column label\n",
    "        - values: what column to be the values\n",
    "    - melt (function): (wide to long), multiple columns to single column\n",
    "        - frame: data\n",
    "        - id_vars: group indicator, the column label will be variable\n",
    "        - value_vars: the value of long form, the column label will be value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Data Aggregation and Group Operations\n",
    "\n",
    "### 1. GroupBy Mechanics\n",
    "    - series.groupby(series or list of series): returns GroupBy object of value with respect to key\n",
    "        - df['value'].groupby(df['key']): one value-one key, Series with Series\n",
    "        - df['value'].groupby([df['key1'], df['key2']]): two key one value, will be hierarchical indexed Series\n",
    "    - dataframe.groupby(series or list of series)\n",
    "        - df.groupby('colkey1'): df -> whole dataframe, colkey -> column of df as key\n",
    "        - df.groupby(['colkey1', 'colkey2']): df -> whole data frame, list of column keys\n",
    "    - dataframe.groupby(series of categorical type): by default it gets excluded, by we can specify it\n",
    "    - for iterations purposes: groupby returns tuple of group name with the chunk of data. name is the label of the key and chunk is dataframe or series\n",
    "        - we can turn it into dictionary\n",
    "        - Seperate the data by key:\n",
    "            - dict(list(df.groupby('key'))): returns a dict that we can access with key label\n",
    "        - Seperate the data by types:\n",
    "            - df.groupby(df.dtypes, axis=1): along row\n",
    "    - grouping by dicts and series: the key is a dict or series\n",
    "        - provide dict that map column label to new column label (for grouping purposes). use axis=1 because we use the columns not rows\n",
    "        - also works if provided by series\n",
    "    - grouping by functions: provide the function to use, index as the decision maker\n",
    "    - grouping by index levels: provide the level, note 0 for row labels and 1 for columns labels. Using index as key\n",
    "### 2. Data Aggregation:\n",
    "    - agg: takes function, slower than the optimized functions\n",
    "        - agg('mean'): same as calling mean\n",
    "        - agg('std'): same as calling std\n",
    "        - if we pass a list of functions, we get dataframe with functions as the column label\n",
    "        - if we pass a list of 2-tuple name-function, the name will become the column label\n",
    "        - if we pass a dict, key represents column name, value represents the functions\n",
    "        - as_index parameter (pass in groupby method), if False will reset the index, the grouping key wont be the index\n",
    "### 3. Apply: General split-apply-combine\n",
    "    - apply: \n",
    "        - general idea: we split the data using keys, then apply the method and pass it to apply as argument, then the data is glued together\n",
    "        - if the function has arguments, we can pass the arguments after function in apply\n",
    "        - group_keys (pass in groupby method), if false the group key is not used as index\n",
    "        - if we pass function which returns dictionary, it works by first split the data by grouping keys, apply the data which returns dict, and the dict passed on to dataframe contructor and making a dataframe or series\n",
    "### 4. Pivot Tables and Cross-Tabulation\n",
    "    - pivot_table (function or method):\n",
    "        - values: which column we want to inspect\n",
    "        - index: grouping key as index\n",
    "        - columns: grouping key as column\n",
    "        - aggfunc: aggregation function\n",
    "        - fill_value: replace missing values \n",
    "        - dropna: if True, do not include columns whose entries are all NA\n",
    "        - margins: add subtotals\n",
    "    - crosstab: special case of pivot_table\n",
    "        - index: the specified grouping key as index\n",
    "        - columns: the specified grouping key as column\n",
    "        - margins: add subtotals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IX. Time Series\n",
    "\n",
    "### 1. Python Built-ins\n",
    "    1. module: datetime\n",
    "    - class: \n",
    "        - datetime: stores both date and time\n",
    "            - construction: datetime(year, month, day, ...)\n",
    "        - timedelta: represents the difference between two datetime values\n",
    "            - construction: timedelta(days, seconds, ...)\n",
    "        - date: store calendar date (y,m,d) using gregorian calendar\n",
    "        - time: store time (h,m,s,ms)\n",
    "        - tzinfo: base type for storing time zone information\n",
    "    - methods:\n",
    "        - now: the current time\n",
    "            - Attributes:\n",
    "                - year\n",
    "                - month\n",
    "                - day\n",
    "                - ...\n",
    "        - datetime.strftime: convert datetime to the specified string format using datetime format specification\n",
    "        - datetime.strptime: convert string to datetime format\n",
    "    - datetime format specification:\n",
    "        - %Y Four-digit year\n",
    "        - %y Two-digit year\n",
    "        - %m Two-digit month [01, 12]\n",
    "        - %d Two-digit day [01, 31]\n",
    "        - %H Hour (24-hour clock) [00, 23]\n",
    "        - %I Hour (12-hour clock) [01, 12]\n",
    "        - %M Two-digit minute [00, 59]\n",
    "        - %S Second [00, 61] (seconds 60, 61 account for leap seconds)\n",
    "        - %w Weekday as integer [0 (Sunday), 6]\n",
    "        - %U Week number of the year [00, 53]; Sunday is considered the first day of the week, and days before the first Sunday of the year are “week 0”\n",
    "        - %W Week number of the year [00, 53]; Monday is considered the first day of the week, and days before the first Monday of the year are “week 0”\n",
    "        - %z UTC time zone offset as +HHMM or -HHMM; empty if time zone naive\n",
    "        - %F Shortcut for %Y-%m-%d (e.g., 2012-4-18)\n",
    "        - %D Shortcut for %m/%d/%y (e.g., 04/18/12)\n",
    "    2. module: dateutil.parser\n",
    "        - functions:\n",
    "            - parse: parse the data from string format to datetime format, using common string representation\n",
    "                - dayfirst: to make sure the day is preciding month\n",
    "    \n",
    "### 2. pandas Time Series\n",
    "    - functions:\n",
    "        - to_datetime: parse common string representation to DatetimeIndex object\n",
    "        - date_range: like np.arange, but for datetime object\n",
    "            - start: the start, lower bound\n",
    "            - end: the end, upper bound\n",
    "            - periods: how many data between start and end\n",
    "            - freq: frequency\n",
    "                - using date offsets by importing from pandas.tseries.offsets import Hour, Minute, Day, ... or using aliases\n",
    "        - period_range: creating range of period objects, returns PeriodIndex object\n",
    "    - methods:\n",
    "        - truncate: slicing data\n",
    "        - resample: convert the sample time series to be fixed specified frequency provides the frequency, ex: D is daily frequency\n",
    "        - (Timestamp method) normalize: using midnight as the start of a day\n",
    "        - to_period: convert to PeriodIndex or Period. For example: if there are three timestamp in same month, then we convert it to Monthly period, each of timestamp will become the corresponding monthly period\n",
    "        - to_timestamp: convert to Timestamp or DatetimeIndex\n",
    "    - class:\n",
    "        - Timestamp: a subtitute of datetime type\n",
    "            - tz: time zone, by default None\n",
    "            - if we write Timestamp('7/2/2019'), it will become american way of writing date. so better year firt\n",
    "        - DatetimeIndex: Index data of datetime type\n",
    "        - Period: return Period object\n",
    "        - PeriodIndex: return PeriodIndex object\n",
    "    - accessing:\n",
    "        - ts[datetime(year, month, day)]\n",
    "        - ts[string_format], ex: ts['21/09/1997']\n",
    "        - ts['year-month-day'], with year, month, and day can be independent\n",
    "        - ts.truncate: slicing the ts\n",
    "            - before: lower bound\n",
    "            - after: upper bound\n",
    "        - ts.loc[DatetimeIndex]\n",
    "### 3. Time Zone Handling\n",
    "    - modules: pytz\n",
    "    - class: \n",
    "        - timezone: create timezone object\n",
    "        - common_timezones: list of common time zones\n",
    "    - methods:\n",
    "        - tz_localize: setting the timezone, ex: series.tz_localize('UTC')\n",
    "        - tz_convert: convert the timezone\n",
    "### 4. Periods and Period Arithmetic\n",
    "    - asfreq: converting period\n",
    "    - ts.to_period: convert the DatetimeIndex to PeriodIndex\n",
    "### 5. Resampling and Frequency Conversion\n",
    "    1. Resampling with Timestamps\n",
    "    - resample (method): think about groupby method!\n",
    "        - rule: takes freq value\n",
    "        - kind: specifies the index type, if period the index will be PeriodIndex, if timestamp the index will be DatetimeIndex\n",
    "        - closed: defines which side is inclusive, ex: if left 00:00 value is included in 00:00 to 00:05 (5min freq)\n",
    "        - label: using which side as the label, right means using boundary from the right as the label\n",
    "        - loffset: shift the index with the specified argument\n",
    "        - convention: 'end'\n",
    "    - agggregation:\n",
    "        - ohlc: returns dataframe containing open(first value in a group), close(last value in a group), high (maximum value within a group), low (minimum value within a group)\n",
    "    - using resample for upsampling:\n",
    "        - ex (from weekly frequency): frame.resample('D').asfreq(), asfreq method tells that we dont do aggreagation\n",
    "        - frame.resample('D').ffill(): ffill method fill the missing values with previous nonnull value\n",
    "            - parameters: limit=how many missing value we want to fill\n",
    "    \n",
    "    2. Resampling with Periods: same thing\n",
    "### 6. Moving Window Functions\n",
    "    - methods:\n",
    "        - rolling: create a moving window, the window is capturing the specified size of samples, doing aggregation and move forward. Works like groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X. Advanced pandas\n",
    "    1. Categorical data\n",
    "    - methods:\n",
    "        - take (for series or dataframe in general): take data (as mapping) with the specified key-value, returns the new data replaced\n",
    "        - as_ordered (for categorical type of data), convert nominal type to ordinal type\n",
    "        - set_categories (data.cat): takes list of object representation, replace the encoded version to object representation\n",
    "        - remove_unused_categories: removing categories that are not present in data\n",
    "        - add_categories: append new (unused) categories at end of existing categories\n",
    "        - as_unordered: negation of as_ordered\n",
    "        - rename_categories: replace categories with indicated set of new category names\n",
    "    - functions:\n",
    "        - pd.get_dummmies: make dummy variable\n",
    "    - class:\n",
    "        - category: pandas.core.categorical.Categorical\n",
    "            - convert to category: data.astype('category')\n",
    "            - attributes:\n",
    "                - categories\n",
    "                - codes\n",
    "            - creation: \n",
    "                - pd.Categorical\n",
    "                - pd.Categorical.from_codes:\n",
    "                    - codes\n",
    "                    - categories\n",
    "                    - ordered: True if categorical type ordinal\n",
    "    - Others:\n",
    "        - accessing codes attribute in a Series or DataFrame, use data.cat.codes\n",
    "        - accessing categories attribute in a Series or DataFrame, use data.cat.categories\n",
    "    2. Groupby advanced\n",
    "        - transform: takes function, ex: g.transform(lambda x: x.mean()), split the data into group, function in transform performs aggregation then the combine step is transform method distribute the mean of each group to its group member\n",
    "        - in timeseries case, we can use resampling method with argument as a key (usually we use offsets). make grouper(level=0, freq='5T'), pass it to groupby method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
